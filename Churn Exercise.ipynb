{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>9000</td>\n",
       "      <td>15810910</td>\n",
       "      <td>Royston</td>\n",
       "      <td>702</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>158527.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>7262</td>\n",
       "      <td>15734578</td>\n",
       "      <td>Craig</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>113537.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28367.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>4718</td>\n",
       "      <td>15580487</td>\n",
       "      <td>Martin</td>\n",
       "      <td>627</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>106922.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84270.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>4732</td>\n",
       "      <td>15622230</td>\n",
       "      <td>Cribb</td>\n",
       "      <td>705</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66331.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6917</th>\n",
       "      <td>6918</td>\n",
       "      <td>15640418</td>\n",
       "      <td>Omeokachie</td>\n",
       "      <td>649</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>115897.73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>143544.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "8999       9000    15810910     Royston          702     Spain  Female   38   \n",
       "7261       7262    15734578       Craig          726    France  Female   53   \n",
       "4717       4718    15580487      Martin          627   Germany    Male   38   \n",
       "4731       4732    15622230       Cribb          705    France  Female   35   \n",
       "6917       6918    15640418  Omeokachie          649   Germany  Female   41   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "8999       9       0.00              2          1               1   \n",
       "7261       1  113537.73              1          0               1   \n",
       "4717       8  106922.92              2          0               1   \n",
       "4731       3       0.00              2          0               1   \n",
       "6917       4  115897.73              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "8999        158527.45       0  \n",
       "7261         28367.21       0  \n",
       "4717         84270.09       0  \n",
       "4731         66331.01       0  \n",
       "6917        143544.48       0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Churn_Modelling.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Histogram against different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0 = df1[df1.Exited == 0]\n",
    "class_1 = df1[df1.Exited == 1]\n",
    "\n",
    "len(class_0), len(class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2088c606ac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure_exited_no = class_0.Tenure\n",
    "tenure_exited_yes = class_1.Tenure\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.hist([tenure_exited_yes, tenure_exited_no], label=['Exited', 'Not Exited'], color=['red', 'green'])\n",
    "plt.xlabel('Tenure')\n",
    "plt.ylabel('No. Of Customers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == 'object':\n",
    "            print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Gender.replace({'Male':0, 'Female':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(data=df1, columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('Geography_Spain', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       1   42       2       0.00              1          1   \n",
       "1          608       1   41       1   83807.86              1          0   \n",
       "2          502       1   42       8  159660.80              3          1   \n",
       "3          699       1   39       1       0.00              2          0   \n",
       "4          850       1   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale=['CreditScore', 'Age', 'Balance', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.538       1  0.324324       2  0.000000              1          1   \n",
       "1        0.516       1  0.310811       1  0.334031              1          0   \n",
       "2        0.304       1  0.324324       8  0.636357              3          1   \n",
       "3        0.698       1  0.283784       1  0.000000              2          0   \n",
       "4        1.000       1  0.337838       2  0.500246              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1         0.506735       1                 1   \n",
       "1               1         0.562709       0                 0   \n",
       "2               0         0.569654       1                 1   \n",
       "3               0         0.469120       0                 1   \n",
       "4               1         0.395400       0                 0   \n",
       "\n",
       "   Geography_Germany  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop('Exited', axis=1)\n",
    "y = df2.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, epcs):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(100, input_shape=(11,), activation='relu'),\n",
    "        keras.layers.Dense(120, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epcs)\n",
    "    \n",
    "    print(\"Model Evaluation : \")\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.4814 - accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.8133\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4168 - accuracy: 0.8221\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8279\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3866 - accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8419\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.8451\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3647 - accuracy: 0.8462\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8510\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3560 - accuracy: 0.8531\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8549\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8541\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8604\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8629\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8637\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8629\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8645\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8680\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8646\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8671\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8689\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.8681\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8665\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8686\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.8668\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3215 - accuracy: 0.8725\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8696\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3182 - accuracy: 0.8708\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.8695\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8691\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8736\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.8698\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8723\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3136 - accuracy: 0.8731\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3136 - accuracy: 0.8727\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3126 - accuracy: 0.8729\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3120 - accuracy: 0.8758\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8719\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3084 - accuracy: 0.8744\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3084 - accuracy: 0.8756\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.8748\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3066 - accuracy: 0.8774\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.8792\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.8785\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8771\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.8785\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.8742\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.8783\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.8776\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.8790\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8790\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.8779\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.8801\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.8839\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2965 - accuracy: 0.8774\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.8808\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.8817\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.8799\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.8823\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.8842\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.8836\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2878 - accuracy: 0.8825\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.8819\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.8836\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.8826\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8838\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.8863\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2847 - accuracy: 0.8846\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.8866\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.8857\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.8873\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2791 - accuracy: 0.8891\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.8870\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8880\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8900\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.8880\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8890\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8907\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8914\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.8919\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8906\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8924\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8915\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8938\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8955\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8935\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2620 - accuracy: 0.8942\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.8932\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.8931\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.8955\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2597 - accuracy: 0.8964\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.8946\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.8960\n",
      "Model Evaluation : \n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8430\n",
      "[0.4140496850013733, 0.8429999947547913]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      1591\n",
      "           1       0.67      0.46      0.54       409\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.77      0.70      0.73      2000\n",
      "weighted avg       0.83      0.84      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ5ElEQVR4nO3debRVZd3A8e9PrikoKnPgFIFgKm+EkKlhmQMglZKkFZoWLggcXjVLVzghpZg4VBqKA762BNQIh9CknJCcUCaFUEGMwAllcIjpXp73j3tAUO4Fi3OPnOf7cbnWuc/e55zfcV2+7rvPuZtIKSFJKn/blHoASVLdMPiSlAmDL0mZMPiSlAmDL0mZqCj1ADVZ/fYrfnxIn1r1W3Ut9QjSRlWuWhg1bfMIX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGfyt1/qVXcUjP73HMCT/52LaRo/7Ifgf3YMnSZQCsXr2a8391Fb1OHMB3ThrIM1NmrNv3/r8+Sq8TB9DrhwPof/b56+4jFcvpp/Vl2tSHmD7tYc44/RQABl/8M6Y891eenTyBB8aPomXLFiWesjwZ/K3UMUcdwfVX/fJj66+/uYgnJ0+lZYvm69b+eO9fABj3h+HceM2lDLv2RtasWUNlZRVDr7meW343lHG3Daddm9aMGntfnb0G5WfffdvTt+8POPCgnnTa/wh6HnU4bdu2ZtiVw+m0/xF07nIk4+//G+cPOqvUo5Ylg7+V6tyxAzvv1PBj67/+7Q2cPbAvER+uzX11Pgd07ghAk0a70HDHHZg5+2VS4Z/lK1aQUuL9D/5N86aN6+gVKEd7770XTz89heXLV1BVVcXEx5/imKO7895776/bZ4cdGpBSKuGU5auiWA8cEXsDRwO7Agl4Dbg3pfSPYj1n7h55/CmaN2vK3nt9foP19m1b88jjT9LjsK/xxluLmPXiHN54cxEd9mnPBeecRq8TB1C//vbsuduunP/TgSWaXjmYOXM2Qy45l8aNG7F8+XJ6dP8Gzz43HYAhl5zLCX16s+zddzn8iO+WeNLyVJQj/Ig4FxgDBPAMMLlwe3REnFfL/fpFxLMR8exNt40uxmhla/mKFYy4bQynnXLix7b16tmNFs2acnzfM7j8NzfQcb8vUK+iHqsrK7lj3HjuGnktj9xzO+3atOamP9xZgumVi9mz53DFFdfxlwdGc/+fb2f6jFlUVVYBcMGFl9O6TRdGjx7HqQN/VOJJy1OxjvD7AvumlFavvxgRVwEzgaEbu1NKaQQwAmD126/4M90n8K+Fr7PwtTc49qTqI/Q3F73Nd398OmNuvIamTRpz7v/2X7dvn/5ns+durZj98lwA9titFQDdDuvKzQZfRTby1jGMvHUMAL8cch4LFry+wfbRY8Zx7z23MfiSK0sxXlkrVvDXAK2Af35kvWVhm7awdm1aM3H8mHVfH3nsSdxx829ptMvOhXP00KD+9jzxzBQq6tWjTes9eWvRO8x9dT6LlyylcaNdePKZqXz+c3uU8FUoB82aNWHRonfYffdWHHNMD77a9du0bduaOXPmAfCtbx7Jiy/OLfGU5alYwT8TeCgiXgb+VVjbA2gLnFak58zKzy4ayuSpM1i69F0OO+YEBvY9kWO/1W2j+y5esoz+Zw0ittmGFs2acNmF5wDQvFkTBvyoDyed+nMqKurR6rPN+dWgn9bly1CG7rrjRho3acTq1ZWcccYgli5dxogbrqBduzasWbOG+fMXMvDUGs/86r8QxXo3PCK2Ab5M9Zu2ASwAJqeUqjbn/p7S0adZ/VZdSz2CtFGVqxZGTduK9imdlNIa4KliPb4k6ZPxc/iSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZMPiSlAmDL0mZqNicnSLiIOBz6++fUrqtSDNJkopgk8GPiD8AbYBpQFVhOQEGX5K2IptzhN8Z2CellIo9jCSpeDbnHP4LwGeLPYgkqbhqPMKPiPuoPnXTEJgVEc8AK9duTyl9u/jjSZK2lNpO6QyrsykkSUVXY/BTSo8BRMTlKaVz198WEZcDjxV5NknSFrQ55/CP2Mhajy09iCSpuGo7hz8AGAi0iYgZ621qCDxR7MEkSVtWbefwRwEPAJcB5623/l5KaXFRp5IkbXGxqY/XR8QeG1tPKc0vykQFbZp28nP/+tRaUbVy0ztJJbBwycyoadvm/OLVeKo/nhnA9kBr4EVg3y0ynSSpTmwy+CmlDut/HRGdgP5Fm0iSVBSf+GqZKaUpQJcizCJJKqLNuXja2et9uQ3QCVhUtIkkSUWxOefwG653u5Lqc/pjizOOJKlYag1+RNQDdkwp/ayO5pEkFUmN5/AjoiKlVEX1KRxJ0lautiP8Z6iO/bSIuBe4C/hg7caU0p+KPJskaQvanHP4jYF3gG/w4efxE2DwJWkrUlvwmxc+ofMCH4Z+LX8LVpK2MrUFvx6wIxuGfi2DL0lbmdqC/3pK6ZI6m0SSVFS1/aZtjRfgkSRtfWoL/mF1NoUkqehqDL7XvJek8vKJL54mSdo6GXxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBLwMtW7Xg9rtv4MEnxvLApLs4ud/3ATjv4jOZ8ORYxj92B8P/bxgNd9oRgF0a7cztd9/AjFcncdHQc0s5ujJw5e+GMP2liTz0xN3r1vbdb2/umzCKCRPHcv/Dd9CxUwcAKioquOb3l/K3v4/j0afu5bSzTinR1OXJ4JeByqoqLr3waroddCy9u5/ECX2Po2271kx69Cl6fPU4en7teObNnc+AM38MwMqVK7nqsuFcdvHVJZ5cObhz9N306d1/g7VBg8/mql//niMPOZZhl13LoMFnA/DNY7rxme225fCDe9H90OM44eTj2G33VqUYuywZ/DKw6M23mTljNgAfvP9v5rw0jxYtmzPp0aeoqqoCYNqzz/PZVs0BWP7vFTz39DRWrVhVspmVj6efeI6lS5ZtsJYSNGxY/RNnw50a8uYbiwrriQYNGlCvXj3qb78dq1et5v33PqjzmctVRakH0Ja16+4t2bdDe6Y/98IG6737HM34uyeUaCppQxf9Yiijxo7ggiHnELENR3fvA8D4eybQ7ahDmTr7UerX356LB/2apUuXbeLRtLnq/Ag/In5Uy7Z+EfFsRDz77oq363KsstBgh/r8/tZhDBl0Je+//+FR0cCz+lJVWck9d91fwumkD/3wx8dz8S8up8t+hzN40OVc+dshAHTcvwNVVWvo9IVD+UrHbvQ/9ST22HO3Ek9bPkpxSmdwTRtSSiNSSp1TSp132r5pXc601auoqOC6kcO454/3M2H8w+vWv3P8Nzn0yK6c9ZPzSzidtKHvfv9o7r/vrwDcd/eD69607dW7J48+NInKykreeXsxk5+eyhe/tG8pRy0rRQl+RMyo4d/ngRbFeM7cDf3Nhcx9aR63DL993doh3ziIfmecTP8TzmTF8hUlnE7a0Juvv8WBB3cB4KuHHMC8V/4JwMIFr3Nw1wMAqN+gPp06f5E5L88r2ZzlJlJKW/5BI94EugFLProJeCKltMm33ds07bTlBytT+x/QkTvH38LsmS+zZs0aAK781bVceOnP+cx227JkcfU50GnPPc8F51wKwGNT/syODXdg22235d133+Pk3gOZ85J/sDbXiqqVpR5hq3HdTVdw4MFdaNxkF95+6x2GDb2OuXNe5ZLLzqOiooIVK1byi3OG8Pz0WTTYoQFXX/tL9mrfhojgjlHjuP53I0v9ErYqC5fMjJq2FSv4NwMjU0qTNrJtVErpB5t6DIOvTzODr0+r2oJflE/ppJT61rJtk7GXJG15fg5fkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjJh8CUpEwZfkjIRKaVSz6A6EBH9UkojSj2H9FF+b9Ydj/Dz0a/UA0g18Huzjhh8ScqEwZekTBj8fHiOVJ9Wfm/WEd+0laRMeIQvSZkw+JKUCYNf5iKie0S8GBFzIuK8Us8jrRURt0TEWxHxQqlnyYXBL2MRUQ+4DugB7AN8PyL2Ke1U0jq3At1LPURODH55+zIwJ6X0SkppFTAGOLrEM0kApJQmAotLPUdODH552xX413pfLyisScqQwS9vsZE1P4crZcrgl7cFwO7rfb0b8FqJZpFUYga/vE0G9oqI1hHxGeB7wL0lnklSiRj8MpZSqgROAx4E/gHcmVKaWdqppGoRMRp4EmgfEQsiom+pZyp3XlpBkjLhEb4kZcLgS1ImDL4kZcLgS1ImDL4kZcLgq2xFRFVETIuIFyLiroho8F881q0R0btw+6baLkIXEV+PiIP+g+d4NSKa/qczSpti8FXOlqeUOqaU9gNWAT9Zf2PhaqKfWErplJTSrFp2+TrwiYMvFZvBVy4eB9oWjr4fiYhRwPMRUS8iroiIyRExIyL6A0S1ayNiVkSMB5qvfaCIeDQiOhdud4+IKRExPSIeiojPUf0/lrMKP110jYhmETG28ByTI+Lgwn2bRMSEiJgaETew8WsfSVtMRakHkIotIiqo/jsB/lJY+jKwX0ppXkT0A5allLpExHbA3yNiAvAloD3QAWgBzAJu+cjjNgNuBA4pPFbjlNLiiLgeeD+lNKyw3yjg6pTSpIjYg+rffP4CcBEwKaV0SUT0BPoV9T+EsmfwVc7qR8S0wu3HgZupPtXyTEppXmH9SOB/1p6fB3YG9gIOAUanlKqA1yLi4Y08/leAiWsfK6VU07XdDwf2iVh3AL9TRDQsPMd3CvcdHxFL/rOXKW0eg69ytjyl1HH9hUJ0P1h/CTg9pfTgR/Y7ik1fSjo2Yx+oPnV6YEpp+UZm8domqjOew1fuHgQGRMS2ABHRLiJ2ACYC3yuc428JHLqR+z4JfC0iWhfu27iw/h7QcL39JlB9ETsK+3Us3JwI9Cms9QAabakXJW2MwVfubqL6/PyUwl+mfQPVP/mOA14GngeGA4999I4ppUVUn3f/U0RMB+4obLoP6LX2TVvgDKBz4U3hWXz4aaHBwCERMYXqU0vzi/QaJcCrZUpSNjzCl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RM/D/Qqw50WWOtkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm, y_sm = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15926, 11), (15926,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm.shape, y_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1593\n",
       "0    1593\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.6061 - accuracy: 0.6670\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.7288\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.7471\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7564\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4781 - accuracy: 0.7669\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.7772\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.7781\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.7831\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.7886\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4422 - accuracy: 0.7897\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4332 - accuracy: 0.7948\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4322 - accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4279 - accuracy: 0.8002\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4240 - accuracy: 0.8031\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4194 - accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4195 - accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.4119 - accuracy: 0.8086\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4109 - accuracy: 0.8092\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4055 - accuracy: 0.8144\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.4037 - accuracy: 0.8133\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.4016 - accuracy: 0.8133\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3993 - accuracy: 0.8127\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3955 - accuracy: 0.8190\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.8207\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8223\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3882 - accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8255\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3820 - accuracy: 0.8261\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3786 - accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8298\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3756 - accuracy: 0.8276\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3687 - accuracy: 0.8334\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3703 - accuracy: 0.8341\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3657 - accuracy: 0.8348\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3641 - accuracy: 0.8352\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8370\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8392\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8426\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3491 - accuracy: 0.8441\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3490 - accuracy: 0.8436\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3452 - accuracy: 0.8458\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3400 - accuracy: 0.8484\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8491\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3368 - accuracy: 0.8516\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3341 - accuracy: 0.8504\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3327 - accuracy: 0.8551\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3284 - accuracy: 0.8529\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3265 - accuracy: 0.8558\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3230 - accuracy: 0.8587\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3209 - accuracy: 0.8582\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3175 - accuracy: 0.8612\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8592\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3138 - accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3107 - accuracy: 0.8629\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3069 - accuracy: 0.8655\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8681\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.8672\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3040 - accuracy: 0.8653\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.8706\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2973 - accuracy: 0.8735\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2963 - accuracy: 0.8680\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.8747\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.8737\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.8747\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.8757\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.8785\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.8797\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8811\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.8780\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.8807\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2736 - accuracy: 0.8825\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2736 - accuracy: 0.8834\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2708 - accuracy: 0.8830\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2676 - accuracy: 0.8875\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2676 - accuracy: 0.8849\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2644 - accuracy: 0.8864\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2667 - accuracy: 0.8863\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2641 - accuracy: 0.8869\n",
      "Epoch 81/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.8905\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2561 - accuracy: 0.8902\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.8890\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.8912\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.8935\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2490 - accuracy: 0.8951\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.8931\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2463 - accuracy: 0.8963\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2488 - accuracy: 0.8949\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2453 - accuracy: 0.8938\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.2452 - accuracy: 0.8958\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.9005\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.2409 - accuracy: 0.8969\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2410 - accuracy: 0.8980\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2371 - accuracy: 0.8991\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2365 - accuracy: 0.9002\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2360 - accuracy: 0.9007\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2331 - accuracy: 0.9016\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2294 - accuracy: 0.9045\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.2347 - accuracy: 0.8994\n",
      "Model Evaluation : \n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8556\n",
      "[0.3682522177696228, 0.8556183576583862]\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1593\n",
      "           1       0.83      0.89      0.86      1593\n",
      "\n",
      "    accuracy                           0.86      3186\n",
      "   macro avg       0.86      0.86      0.86      3186\n",
      "weighted avg       0.86      0.86      0.86      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predictions = ANN(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6370\n",
       "1    1630\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2123.3333333333335"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6370/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df2[df2['Exited'] == 0]\n",
    "class_1 = df2[df2['Exited'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6370, 1630)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_0), len(class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    \n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "    \n",
    "    X_train = df_train.drop('Exited', axis=1)\n",
    "    y_train = df_train['Exited']\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.6602 - accuracy: 0.6071\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6592\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.6844\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7067\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7288\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7328\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7387\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7583\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7564\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7666\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7669\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4827 - accuracy: 0.7635\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7681\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.7638\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7696\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7709\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4630 - accuracy: 0.7788\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4528 - accuracy: 0.7810\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7742\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7761\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7813\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7748\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7798\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4421 - accuracy: 0.7874\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7899\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7844\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7896\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7917\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7926\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7948\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7988\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7917\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7926\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8031\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8012\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7988\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8043\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8052\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8052\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8071\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8107\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8052\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8067\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8092\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8058\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8098\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8147\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8113\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8160\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8184\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8104\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8132\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8190\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8166\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8184\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8242\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8230\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8267\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8178\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8178\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8252\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8166\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8273\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8242\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3738 - accuracy: 0.8196\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3731 - accuracy: 0.8298\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3701 - accuracy: 0.8236\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8252\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3675 - accuracy: 0.8273\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3668 - accuracy: 0.8252\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8279\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3660 - accuracy: 0.8301\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8313\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8264\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8313\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8365\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8319\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8362\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8408\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8362\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8365\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8390\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8423\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8393\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8393\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8442\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8417\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8445\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8380\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.8383\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8423\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8460\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8466\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8414\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8528\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8482\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8525\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8463\n",
      "Model Evaluation : \n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7905\n",
      "[0.5128650665283203, 0.7904999852180481]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      1593\n",
      "           1       0.49      0.68      0.57       407\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.70      0.75      0.71      2000\n",
      "weighted avg       0.82      0.79      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(class_0, class_1, 0, 1630)\n",
    "y_preds_1 = ANN(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.6095\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6908\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7046\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7279\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7322\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7429\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7417\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7497\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7610\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7620\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7604\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7687\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7644\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7721\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7709\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7666\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7687\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4651 - accuracy: 0.7706\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7706\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7764\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7810\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7782\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7745\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7791\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7798\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7813\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7844\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7764\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7813\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7834\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7868\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7871\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7825\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7856\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7850\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7911\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7887\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7911\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7908\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7994\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7936\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7975\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7936\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7963\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8009\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8009\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8015\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7951\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7997\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8018\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8052\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8006\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8025\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8018\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8025\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8098\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8058\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8144\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8028\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8138\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8028\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8117\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8086\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8138\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8043\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8113\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8138\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8098\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8160\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8190\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8163\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8138\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8071\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8206\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8141\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8160\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8202\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8175\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8224\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8248\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8261\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8267\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8215\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8239\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8276\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8258\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8322\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8255\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8206\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8285\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8270\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8221\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8294\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8319\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8282\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8258\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8319\n",
      "Model Evaluation : \n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.8010\n",
      "[0.4880125820636749, 0.8009999990463257]\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      1593\n",
      "           1       0.51      0.64      0.57       407\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.71      0.74      0.72      2000\n",
      "weighted avg       0.82      0.80      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(class_0, class_1, 1630, 1630*2)\n",
    "y_preds_2 = ANN(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 0.6556 - accuracy: 0.6126\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6509\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6963\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7067\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7209\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7359\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7463\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7583\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7626\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7730\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7678\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7724\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7773\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7776\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7807\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7791\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7828\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7893\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7807\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7850\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7926\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7880\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7914\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7914\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7911\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7902\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7908\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7902\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8003\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8012\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7997\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8012\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7982\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7960\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8043\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7966\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8015\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8018\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8061\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4132 - accuracy: 0.8055\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8043\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4089 - accuracy: 0.8083\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8107\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8129\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8147\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8147\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8123\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8153\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8132\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8144\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8169\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8126\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8187\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8190\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8169\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8206\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8298\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8276\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8242\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8236\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8264\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8245\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8270\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8276\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8331\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8301\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8328\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8353\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8325\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8353\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8331\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8334\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8316\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8365\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8393\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8368\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8390\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8353\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8374\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8402\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8414\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8405\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8402\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8433\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8439\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8472\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8472\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8497\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8500\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8537\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8460\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8485\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8488\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8497\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8475\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8528\n",
      "Model Evaluation : \n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7600\n",
      "[0.5815005898475647, 0.7599999904632568]\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84      1593\n",
      "           1       0.45      0.73      0.55       407\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.68      0.75      0.69      2000\n",
      "weighted avg       0.82      0.76      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(class_0, class_1, 1630*2, 1630*3)\n",
    "y_preds_3 = ANN(X_train, y_train, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_preds_1.copy()\n",
    "\n",
    "for i in range(len(y_pred_final)):\n",
    "    n_ones = y_preds_1[i] + y_preds_2[i] + y_preds_3[i]\n",
    "    \n",
    "    if n_ones > 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.87      1593\n",
      "           1       0.50      0.68      0.58       407\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.70      0.75      0.72      2000\n",
      "weighted avg       0.83      0.80      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
